{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from hansolo import *\n",
    "import psutil\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "#retrieve the dataset\n",
    "digits = datasets.load_digits()\n",
    "images=digits.images/16 #(1797,8,8)\n",
    "target=digits.target #(1797,)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
    "M_train = np.shape(X_train)[0]\n",
    "M_test = np.shape(X_test)[0]\n",
    "\n",
    "# Reshape images and compute probabilities\n",
    "flattened_images_train = X_train.reshape((M_train, -1))\n",
    "flattened_images_test = X_test.reshape((M_test, -1))\n",
    "\n",
    "#network parameters\n",
    "M0 = 40 #number of images to train hidden layer\n",
    "M0_sel = 40 #number of images to select hidden neurons\n",
    "M_out = M_train - M0 - M0_sel #number of images to train output layer\n",
    "M_tot = M0 + M0_sel + M_out + M_test\n",
    "\n",
    "N = 2000 #number of time steps\n",
    "p = 1  # spiking proba input neurons if pixel is black\n",
    "nu = 0.5 # bias\n",
    "\n",
    "\n",
    "K_input = 64 #number of input neurons\n",
    "\n",
    "K_mid = int(K_input * (K_input - 1)/2) #number of hidden neurons before selection\n",
    "#K_mid_new = 120\n",
    "\n",
    "K_output = 10 #number of output neurons\n",
    "eta_mid = 3 #parameter EWA for hidden neurons\n",
    "expert1 = 'PWA' #expert of hidden layer\n",
    "para_PWA = 2 #parameter PWA \n",
    "\n",
    "expert2 = 'PWA' #expert of output layer\n",
    "\n",
    "indices = np.arange(K_input)\n",
    "i, j = np.meshgrid(indices, indices)\n",
    "mask = i < j\n",
    "l_mid = np.column_stack((i[mask], j[mask])) #tensor indices of hidden neurons\n",
    "\n",
    "eta_output = 0.002 #parameter EWA for output neurons\n",
    "\n",
    "images_mid = flattened_images_train[:M0+M0_sel,:] /16\n",
    "images_out = flattened_images_train[M0+M0_sel:M0+M0_sel+M_out,:] /16\n",
    "images_test = flattened_images_test /16\n",
    "\n",
    "target_out = y_train[M_train - M_out:]\n",
    "target_test = y_test\n",
    "Nb_simu = 20 #number of simulations\n",
    "\n",
    "accuracy = np.zeros((Nb_simu))\n",
    "\n",
    "for K_mid_new in np.arange(10,210,10): #number of selected neurons hidden layer\n",
    "    for nb in range(Nb_simu):\n",
    "    #Simulation input neurons\n",
    "        prob =  np.transpose(np.array([p*images_mid for i in range(N)]), axes = (2,0,1))\n",
    "    # Input Neurons activity (K_input,N,M)\n",
    "\n",
    "        input_neurons_mid = stats.bernoulli.rvs(prob) #to train mid neurons\n",
    "\n",
    "    #to train output neurons\n",
    "        prob_input = np.transpose(np.array([p*images_out for i in range(N)]), axes = (2,0,1))\n",
    "        input_neurons_out = stats.bernoulli.rvs(prob_input)\n",
    "        prob_input = np.transpose(np.array([p*images_test for i in range(N)]), axes = (2,0,1))\n",
    "        input_neurons_test = stats.bernoulli.rvs(prob_input) #to test\n",
    "    #Parameters mid neurons\n",
    "        W_mid = np.zeros((K_mid,K_input,M0))\n",
    "        W_mid[:,:,0] = 1/K_input\n",
    "        W_mid_not_renorm = np.zeros((K_mid, K_input, M0))\n",
    "        W_mid_not_renorm[:, :, 0] += 1\n",
    "\n",
    "        cum_gain_mid = np.zeros((K_mid))\n",
    "        cum_gain_input_to_mid = np.zeros((K_mid,K_input))\n",
    "\n",
    "    #training mid neurons\n",
    "\n",
    "        for m in range(M0-1):\n",
    "        \n",
    "            gain_mid = GainMid(np.arange(K_mid),K_mid,K_input,input_neurons_mid[:,:,m], l_mid) #(K_mid,K_input)\n",
    "            cum_gain_input_to_mid += gain_mid\n",
    "            cum_gain_mid += np.sum(W_mid[:,:,m] * gain_mid, axis = 1)\n",
    "\n",
    "            if expert1 == \"EWA\" and m < M0-1:\n",
    "                W_mid_not_renorm[:, :, m + 1] = EWA(W_mid_not_renorm[:, :, m], eta_mid, gain_mid)\n",
    "                W_mid[:, :, m + 1] = (W_mid_not_renorm[:, :, m + 1].T / np.sum(W_mid_not_renorm[:, :, m + 1], axis=1)).T\n",
    "            #W_mid[:, :, m+1] = 1/K_mid\n",
    "                \n",
    "            else:\n",
    "                W_mid_not_renorm[:, :, m + 1] = PWA(para_PWA, K_mid, K_input, cum_gain_mid, cum_gain_input_to_mid) \n",
    "                not_zero = np.where(np.sum(W_mid_not_renorm[:,:,m+1], axis = 1) != 0)[0]\n",
    "                zero = np.where(np.sum(W_mid_not_renorm[:,:,m+1], axis = 1) == 0)[0]\n",
    "                W_mid[not_zero, :, m + 1] = (W_mid_not_renorm[not_zero, :, m + 1].T / np.sum(W_mid_not_renorm[not_zero, :, m + 1], axis=1)).T\n",
    "                W_mid[zero, :, m+1] = 1/K_input\n",
    "\n",
    "        #print(nb,\"mid neurons trained\")\n",
    "\n",
    "    #selection mid neurons\n",
    "\n",
    "        prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid[:,:,M0-1], input_neurons_mid[:, :, M0:M0 + M0_sel])\n",
    "        clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "        mid_neurons_sel = stats.bernoulli.rvs(clipped_probas_mid)\n",
    "        P_mid = np.sum(mid_neurons_sel, axis=1) / N\n",
    "        max_P = np.max(P_mid, axis = 1 )\n",
    "        max_P_sorted = np.sort(max_P)\n",
    "\n",
    "        x = max_P_sorted[K_mid-K_mid_new] \n",
    "        mid_neur_ok = np.where(max_P > x)[0] #selected neurons\n",
    "        missing = K_mid_new - np.shape(mid_neur_ok)[0]\n",
    "        mid_neur_to_sel = np.where(max_P == x)[0]\n",
    "        n_tot = np.shape(mid_neur_to_sel)[0]\n",
    "        selected_indices = np.random.choice(n_tot, size=missing, replace=False) #random choice of neurons which have the same nb of spikes\n",
    "        mid_neur_missing = mid_neur_to_sel[selected_indices]\n",
    "\n",
    "        mid_neur = np.concatenate((mid_neur_missing, mid_neur_ok))\n",
    "        mid_neur = np.sort(mid_neur)\n",
    "\n",
    "\n",
    "        prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid[mid_neur,:,M0-1], input_neurons_out)\n",
    "        clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "        mid_neurons_out=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "        P_mid = np.sum(mid_neurons_out, axis = 1) / N\n",
    "\n",
    "    #parameters output\n",
    "    \n",
    "        cum_gain_output = np.zeros((K_output))\n",
    "        cum_gain_mid2_to_output = np.zeros((K_output, K_mid_new))\n",
    "\n",
    "        W_output = np.zeros((K_output, K_mid_new, M_out))\n",
    "        W_output_not_renorm = np.zeros((K_output, K_mid_new, M_out))\n",
    "        W_output[:, :, 0] += 1/K_mid_new\n",
    "        W_output_not_renorm[:, :, 0] += 1\n",
    "\n",
    "    #training output\n",
    "\n",
    "        for m in range(M_out-1):\n",
    "            gain_output = GainOutput(K_output, K_mid_new, P_mid[:,m], target_out[m]) \n",
    "            cum_gain_mid2_to_output += gain_output\n",
    "            cum_gain_output += np.sum(W_output[:, :, m] * gain_output, axis = 1)\n",
    "            \n",
    "\n",
    "            if expert2 == \"EWA\":\n",
    "                W_output_not_renorm[ :, :, m+1] = EWA(W_output_not_renorm[:, :, m], eta_output, gain_output)\n",
    "                W_output[:,:, m+1] = (W_output_not_renorm[:, :, m+1].T / np.sum(W_output_not_renorm[:, :, m + 1], axis = 1)).T\n",
    "\n",
    "            else:\n",
    "                W_output_not_renorm[:, :, m+1] = PWA(para_PWA, K_output, K_mid_new, cum_gain_output, cum_gain_mid2_to_output)\n",
    "                \n",
    "                not_zero = np.where(np.sum(W_output_not_renorm[:,:,m+1], axis = 1) != 0)[0]\n",
    "                zero = np.where(np.sum(W_output_not_renorm[:,:,m+1], axis = 1) == 0)[0]\n",
    "                W_output[not_zero,:, m + 1] = (\n",
    "                    W_output_not_renorm[not_zero, :, m + 1].T / np.sum(W_output_not_renorm[not_zero,:, m + 1], axis=1)\n",
    "                    ).T\n",
    "                W_output[zero,:, m+1] = 1/K_mid_new\n",
    "\n",
    "        #print(nb, 'output neurons trained')\n",
    "\n",
    "    #test with new images\n",
    "        prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid[mid_neur,:,M0-1], input_neurons_test)\n",
    "        clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "        mid_neurons_test=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "        answers_test = np.zeros((M_test))\n",
    "        for m in range(M_test):\n",
    "        \n",
    "        # Simulation output neurons (without Kalikow)\n",
    "            probas_output = np.sum(W_output[:,None,:,- 1] * mid_neurons_test[:,:,m].T, axis = 2)\n",
    "            probas_output = np.clip(probas_output, 0, 1)\n",
    "            output_neurons = stats.bernoulli.rvs(probas_output)\n",
    "\n",
    "            P_output = np.sum(output_neurons, axis = 1) / N\n",
    "            chosen_class = np.where(P_output == np.max(P_output))[0]\n",
    "\n",
    "            if chosen_class[0] == target_test[m]:\n",
    "                answers_test[m] = 1\n",
    "        accuracy[nb] = np.sum(answers_test)/M_test\n",
    "\n",
    "    #np.save(f\"accuracy_{expert1}_{expert2}_{K_mid_new}_{eta_output}_20\", accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
