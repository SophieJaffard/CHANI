{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.special as spe\n",
    "from hansolo import *\n",
    "import psutil\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#retrieve dataset\n",
    "digits = datasets.load_digits()\n",
    "images=digits.images/16 #(1797,8,8)\n",
    "target=digits.target #(1797,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
    "M_train = np.shape(X_train)[0]\n",
    "M_test = np.shape(X_test)[0]\n",
    "\n",
    "# Reshape images and compute probabilities\n",
    "flattened_images_train = X_train.reshape((M_train, -1))\n",
    "flattened_images_test = X_test.reshape((M_test, -1))\n",
    "\n",
    "eta_mid = 3 #parameter EWA 1st hidden layer\n",
    "expert1 = 'EWA' #expert 1st hidden layer\n",
    "\n",
    "eta_mid2 = 3 #parameter EWA 2nd hidden layer\n",
    "expert2 = 'EWA' #expert 2nd hidden layer\n",
    "\n",
    "eta_output = 0.03 #parameter EWA output layer\n",
    "expert3 = 'EWA' #expert output layer\n",
    "\n",
    "M0 = 40 #number of images to train 1st hidden layer\n",
    "M0_sel = 40 #number of images to select neurons 1st hidden layer\n",
    "M1 = 40 #number of images to train 2nd hidden layer\n",
    "M1_sel = 40 #number of images to select hidden neurons 2nd layer\n",
    "M_mid = M0 + M0_sel + M1 + M1_sel\n",
    "M_out = M_train - M_mid #number of images to train output neurons\n",
    "M_tot = M_mid + M_out + M_test\n",
    "\n",
    "N = 2000 #number of time steps\n",
    "p = 1  # spiking proba input neurons \n",
    "nu = 0.5 # bias\n",
    "\n",
    "K_input = 64 #number of input neurons\n",
    "\n",
    "K_mid_new = 100 #number of selected neurons 1st hidden layer\n",
    "K_mid2_new = 150 #number of selected neurons 2nd hidden layer\n",
    "\n",
    "K_mid = int(K_input * (K_input - 1)/2) #number of neurons 1st hidden layer before selection\n",
    "K_output = 10  #number of output neurons\n",
    "\n",
    "images_mid = flattened_images_train[:M_mid,:] /16 \n",
    "images_out = flattened_images_train[M_mid:M_mid+M_out,:] /16\n",
    "images_test = flattened_images_test /16\n",
    "\n",
    "target_out = y_train[M_mid:]\n",
    "target_test = y_test\n",
    "\n",
    "def same_corr(a,b):\n",
    "    return a[0] == b[0] or a[0] == b[1] or a[1] == b[0] or a[1] == b[1]\n",
    "        \n",
    "indices = np.arange(K_input)\n",
    "i, j = np.meshgrid(indices, indices)\n",
    "mask = i < j\n",
    "l_mid = np.column_stack((i[mask], j[mask])) #tensor indices hidden neurons 1st layer\n",
    "\n",
    "Nb = 10 #number of simulations\n",
    "accuracy = np.zeros((Nb))\n",
    "for nb in range(Nb):\n",
    "    #simulation input neurons\n",
    "\n",
    "    prob =  np.transpose(np.array([p*images_mid for i in range(N)]), axes = (2,0,1))\n",
    "\n",
    "    # Input Neurons activity (K_input,N,M)\n",
    "\n",
    "    input_neurons_mid = stats.bernoulli.rvs(prob)\n",
    "    prob_input = np.transpose(np.array([p*images_out for i in range(N)]), axes = (2,0,1))\n",
    "\n",
    "    input_neurons_out = stats.bernoulli.rvs(prob_input)\n",
    "\n",
    "    prob_input = np.transpose(np.array([p*images_test for i in range(N)]), axes = (2,0,1))\n",
    "    input_neurons_test = stats.bernoulli.rvs(prob_input)\n",
    "\n",
    "    #M0 = 30 #number of images for training of mid neurons\n",
    "\n",
    "    cum_gain_mid = np.zeros((K_mid))\n",
    "    cum_gain_input_to_mid = np.zeros((K_mid,K_input))\n",
    "\n",
    "    #training mid neurons\n",
    "\n",
    "    cum_gain_EWA = np.zeros((K_mid, K_input))\n",
    "\n",
    "    for m in range(M0-1):\n",
    "        gain = GainMid(np.arange(K_mid),K_mid,K_input,input_neurons_mid[:,:,m], l_mid)\n",
    "        cum_gain_EWA += gain\n",
    "        #print(m)\n",
    "    if expert1 == 'EWA':\n",
    "        W_mid_end = spe.softmax(eta_mid * cum_gain_EWA, axis = 1)\n",
    "    \n",
    "\n",
    "    #selection mid \n",
    "\n",
    "    prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid_end, input_neurons_mid[:, :, M0:M0 + M0_sel])\n",
    "    clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "    mid_neurons_sel = stats.bernoulli.rvs(clipped_probas_mid)\n",
    "    P_mid = np.sum(mid_neurons_sel, axis=1) / N\n",
    "    max_P = np.max(P_mid, axis = 1 )\n",
    "    max_P_sorted = np.sort(max_P)\n",
    "\n",
    "    x = max_P_sorted[K_mid-K_mid_new] \n",
    "    mid_neur_ok = np.where(max_P > x)[0] #selected neurons\n",
    "    missing = K_mid_new - np.shape(mid_neur_ok)[0]\n",
    "    mid_neur_to_sel = np.where(max_P == x)[0]\n",
    "    n_tot = np.shape(mid_neur_to_sel)[0]\n",
    "    selected_indices = np.random.choice(n_tot, size=missing, replace=False) #random choice of neurons which have the same nb of spikes\n",
    "    mid_neur_missing = mid_neur_to_sel[selected_indices]\n",
    "\n",
    "    mid_neur = np.concatenate((mid_neur_missing, mid_neur_ok))\n",
    "    mid_neur = np.sort(mid_neur)\n",
    "\n",
    "    #simu mid neurons\n",
    "    prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid_end[mid_neur,:], input_neurons_mid[ :, :, M0+M0_sel:])\n",
    "    clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "    mid_neurons_mid2=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "    #mid2\n",
    "    l_mid2 = []\n",
    "    for i in range(K_mid_new):\n",
    "        for j in range(K_mid_new):\n",
    "            if i < j and not same_corr(l_mid[mid_neur[i]], l_mid[mid_neur[j]]):\n",
    "                l_mid2.append([i,j])\n",
    "    l_mid2 = np.array(l_mid2)\n",
    "    K_mid2 = np.shape(l_mid2)[0]\n",
    "\n",
    "    cum_gain_mid_to_mid2 = np.zeros((K_mid2,K_mid_new))\n",
    "\n",
    "    for m in range(M1-1):\n",
    "        gain_mid2 = GainMid(np.arange(K_mid2),K_mid2,K_mid_new,mid_neurons_mid2[:,:,m], l_mid2) #(K_mid,K_input) a vectoriser !\n",
    "        cum_gain_mid_to_mid2 += gain_mid2\n",
    "        #print(m)\n",
    "    \n",
    "    if expert2 == \"EWA\":\n",
    "        W_mid2_end = spe.softmax(eta_mid2 * cum_gain_mid_to_mid2, axis = 1)\n",
    "\n",
    "    #selection mid2\n",
    "        \n",
    "    prob_mid2 = -nu + np.einsum('ai, itm -> atm', W_mid2_end, mid_neurons_mid2[:, :, M1:M1+M1_sel])\n",
    "    clipped_probas_mid2 = np.clip(prob_mid2, 0, 1)\n",
    "    mid2_neurons_sel= stats.bernoulli.rvs(clipped_probas_mid2)\n",
    "    P_mid2 = np.sum(mid2_neurons_sel, axis=1) / N\n",
    "    max_P2 = np.max(P_mid2, axis = 1 )\n",
    "    max_P2_sorted = np.sort(max_P2)\n",
    "\n",
    "    x = max_P2_sorted[K_mid2-K_mid2_new] \n",
    "    mid2_neur_ok = np.where(max_P2 > x)[0] #selected neurons\n",
    "    missing2 = K_mid2_new - np.shape(mid2_neur_ok)[0]\n",
    "    mid2_neur_to_sel = np.where(max_P2 == x)[0]\n",
    "    n_tot2 = np.shape(mid2_neur_to_sel)[0]\n",
    "    selected_indices = np.random.choice(n_tot2, size=missing2, replace=False) #random choice of neurons which have the same nb of spikes\n",
    "    mid2_neur_missing = mid2_neur_to_sel[selected_indices]\n",
    "\n",
    "    mid2_neur = np.concatenate((mid2_neur_missing, mid2_neur_ok))\n",
    "    mid2_neur = np.sort(mid2_neur)\n",
    "\n",
    "    prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid_end[mid_neur,:], input_neurons_out)\n",
    "    clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "    mid_neurons_out=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "    prob_mid2 = -nu + np.einsum('ai, itm -> atm', W_mid2_end[mid2_neur,:], mid_neurons_out)\n",
    "    clipped_probas_mid2 = np.clip(prob_mid2, 0, 1)\n",
    "    mid2_neurons_out=stats.bernoulli.rvs(clipped_probas_mid2)\n",
    "\n",
    "        \n",
    "    P_mid2 = np.sum(mid2_neurons_out, axis = 1) / N\n",
    "\n",
    "    #simu test\n",
    "    prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid_end[mid_neur,:], input_neurons_test)\n",
    "    clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "    mid_neurons_test=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "    prob_mid2 = -nu + np.einsum('ai, itm -> atm', W_mid2_end[mid2_neur,:], mid_neurons_test)\n",
    "    clipped_probas_mid2 = np.clip(prob_mid2, 0, 1)\n",
    "    mid2_neurons_test=stats.bernoulli.rvs(clipped_probas_mid2)\n",
    "\n",
    "    cum_gain_mid2_to_output = np.zeros((K_output, K_mid2_new))\n",
    "\n",
    "    for m in range(M_out-1):\n",
    "        gain_output = GainOutput(K_output, K_mid2_new, P_mid2[:,m], target_out[m]) \n",
    "        cum_gain_mid2_to_output += gain_output\n",
    "        \n",
    "    if expert3 == \"EWA\":\n",
    "        W_output_end = spe.softmax(eta_output * cum_gain_mid2_to_output, axis =1 )\n",
    "\n",
    "    #test new images\n",
    "\n",
    "    answers_test = np.zeros((M_test))\n",
    "\n",
    "    for m in range(M_test):\n",
    "        \n",
    "        # Simulation output neurons (without Kalikow)\n",
    "        probas_output = np.sum(W_output_end[:,None,:] * mid2_neurons_test[:,:,m].T, axis = 2)\n",
    "        probas_output = np.clip(probas_output, 0, 1)\n",
    "        output_neurons = stats.bernoulli.rvs(probas_output)\n",
    "\n",
    "        P_output = np.sum(output_neurons, axis = 1) / N\n",
    "        chosen_class = np.where(P_output == np.max(P_output))[0]\n",
    "\n",
    "        if chosen_class[0] == target_test[m]:\n",
    "            answers_test[m] = 1\n",
    "    accuracy[nb] = np.sum(answers_test)/M_test\n",
    "    print(nb, accuracy[nb])\n",
    "\n",
    "#np.save(f\"accuracy2mid_EWA_{K_mid2_new}_{eta_output}_10\", accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
