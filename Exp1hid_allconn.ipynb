{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.special as spe\n",
    "from hansolo import *\n",
    "import psutil\n",
    "\n",
    "# sklearn includes a complement of datasets which can be used\n",
    "# to explore different types of machine learning examples\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#retrieve dataset\n",
    "digits = datasets.load_digits()\n",
    "images=digits.images/16 #(1797,8,8)\n",
    "target=digits.target #(1797,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
    "M_train = np.shape(X_train)[0]\n",
    "M_test = np.shape(X_test)[0]\n",
    "\n",
    "# Reshape images and compute probabilities\n",
    "flattened_images_train = X_train.reshape((M_train, -1))\n",
    "flattened_images_test = X_test.reshape((M_test, -1))\n",
    "\n",
    "M0 = 40 #number of images to train hidden layer\n",
    "M0_sel = 40 #number of images to select hidden neurons\n",
    "M_out = M_train - M0 - M0_sel #number of images to train output neurons\n",
    "M_tot = M0 + M0_sel + M_out + M_test\n",
    "\n",
    "N = 2000 #number of time steps\n",
    "p = 1  # spiking proba input neurons when pixel is black\n",
    "nu = 0.5 # bias\n",
    "\n",
    "K_input = 64 #number of input neurons\n",
    "K_mid = int(K_input * (K_input - 1)/2) #number of hidden neurons before selection\n",
    "#K_mid_new = 200\n",
    "\n",
    "K_output = 10  #number of output neurons\n",
    "eta_mid = 3 #parameter EWA hidden neurons\n",
    "expert1 = 'EWA' #expert hidden layer\n",
    "para_PWA = 2 #parameter PWA \n",
    "\n",
    "expert2 = 'EWA' #expert output layer\n",
    "\n",
    "indices = np.arange(K_input)\n",
    "i, j = np.meshgrid(indices, indices)\n",
    "mask = i < j\n",
    "l_mid = np.column_stack((i[mask], j[mask])) #tensor indices hidden neurons\n",
    "\n",
    "eta_output = 0.007 #parameter EWA output neurons\n",
    "\n",
    "param = 0.7 #param to renormalize input neurons gains for output\n",
    "param2 = 0.25 #param to renormalize output activity\n",
    "\n",
    "images_mid = flattened_images_train[:M0+M0_sel,:] /16 #images to train mid neurons\n",
    "images_out = flattened_images_train[M0+M0_sel:M0+M0_sel+M_out,:] /16 #images to train output neurons\n",
    "images_test = flattened_images_test /16 #test images\n",
    "\n",
    "target_out = y_train[M_train - M_out:] #labels of train images\n",
    "target_test = y_test #labels of test images\n",
    "Nb_simu = 10 #number of simulations\n",
    "\n",
    "accuracy = np.zeros((Nb_simu))\n",
    "\n",
    "for K_mid_new in 10* np.arange(1,10): #number of selected neurons hidden layerS\n",
    "    print(K_mid_new)\n",
    "    K_tot = K_mid_new + K_input\n",
    "    for nb in range(Nb_simu):\n",
    "    #Simulation input neurons\n",
    "        prob =  np.transpose(np.array([p*images_mid for i in range(N)]), axes = (2,0,1))\n",
    "\n",
    "    # Input Neurons activity (K_input,N,M)\n",
    "        input_neurons_mid = stats.bernoulli.rvs(prob) #to train mid neurons\n",
    "\n",
    "    #to train output neurons\n",
    "\n",
    "        prob_input = np.transpose(np.array([p*images_out for i in range(N)]), axes = (2,0,1))\n",
    "        input_neurons_out = stats.bernoulli.rvs(prob_input)\n",
    "\n",
    "    #to test\n",
    "        prob_input = np.transpose(np.array([p*images_test for i in range(N)]), axes = (2,0,1))\n",
    "        input_neurons_test = stats.bernoulli.rvs(prob_input) #to test\n",
    "\n",
    "    #training mid neurons\n",
    "        \n",
    "        cum_gain_EWA = np.zeros((K_mid, K_input))\n",
    "        for m in range(M0):\n",
    "            gain = GainMid(np.arange(K_mid),K_mid,K_input,input_neurons_mid[:,:,m], l_mid)\n",
    "            cum_gain_EWA += gain\n",
    "\n",
    "        if expert1 == 'EWA':\n",
    "            W_mid_end = spe.softmax(eta_mid * cum_gain_EWA, axis = 1)\n",
    "\n",
    "    #selection mid neurons\n",
    "\n",
    "    #simulation of mid neurons activity to select\n",
    "        prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid_end, input_neurons_mid[:, :, M0:M0 + M0_sel])\n",
    "        clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "        mid_neurons_sel = stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "    #selection\n",
    "        P_mid = np.sum(mid_neurons_sel, axis=1) / N\n",
    "        max_P = np.max(P_mid, axis = 1 )\n",
    "        max_P_sorted = np.sort(max_P)\n",
    "\n",
    "        x = max_P_sorted[K_mid-K_mid_new] \n",
    "        mid_neur_ok = np.where(max_P > x)[0] #selected neurons\n",
    "        missing = K_mid_new - np.shape(mid_neur_ok)[0]\n",
    "        mid_neur_to_sel = np.where(max_P == x)[0]\n",
    "        n_tot = np.shape(mid_neur_to_sel)[0]\n",
    "        selected_indices = np.random.choice(n_tot, size=missing, replace=False) #random choice of neurons which have the same nb of spikes\n",
    "        mid_neur_missing = mid_neur_to_sel[selected_indices]\n",
    "\n",
    "        mid_neur = np.concatenate((mid_neur_missing, mid_neur_ok))\n",
    "        mid_neur = np.sort(mid_neur)\n",
    "\n",
    "        prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid_end[mid_neur,:], input_neurons_out)\n",
    "        clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "        mid_neurons_out=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "        P_mid = np.sum(mid_neurons_out, axis = 1) / N\n",
    "        P_input = np.sum(input_neurons_out, axis = 1) / N\n",
    "\n",
    "    \n",
    "    #training output\n",
    "        if expert2 == 'EWA':\n",
    "            cum_gain_EWA = np.zeros((K_output, K_tot))\n",
    "            for m in range(M_out-1):\n",
    "                gain = GainOutputAllConnected(K_output, K_mid_new, K_input, param, P_mid[:,m], P_input[:,m], target_out[m])\n",
    "                cum_gain_EWA += gain\n",
    "            W_output_end = spe.softmax(eta_output * cum_gain_EWA, axis = 1)\n",
    "\n",
    "    #test with new images\n",
    "\n",
    "        prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid_end[mid_neur,:], input_neurons_test)\n",
    "        clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "        mid_neurons_test=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "        answers_test = np.zeros((M_test))\n",
    "\n",
    "        for m in range(M_test):\n",
    "            activity_tot = np.concatenate((mid_neurons_test[:,:,m], param2 * input_neurons_test[:,:,m]), axis = 0) \n",
    "        # Simulation output neurons \n",
    "            probas_output = np.sum(W_output_end[:,None,:] * activity_tot.T, axis = 2)\n",
    "            probas_output = np.clip(probas_output, 0, 1)\n",
    "            output_neurons = stats.bernoulli.rvs(probas_output)\n",
    "\n",
    "            P_output = np.sum(output_neurons, axis = 1) / N\n",
    "            chosen_class = np.where(P_output == np.max(P_output))[0]\n",
    "\n",
    "            if chosen_class[0] == target_test[m]:\n",
    "                answers_test[m] = 1\n",
    "        accuracy[nb] = np.sum(answers_test)/M_test\n",
    "        print(nb, accuracy[nb])\n",
    "\n",
    "    #np.save(f\"accuracy_all_{expert1}_{expert2}_{K_mid_new}_{eta_output}_10\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
