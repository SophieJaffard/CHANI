{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cafd6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from hansolo import *\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750342a",
   "metadata": {},
   "source": [
    "Zero hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e511201",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000 #number of timesteps\n",
    "p = 0.5 # spiking proba input neurons \n",
    "nu = 0.5 # bias\n",
    "\n",
    "K_input = 6 #number of input neurons\n",
    "\n",
    "K_output = 2  #number of output neurons\n",
    "\n",
    "para_PWA = 2 #parameter expert PWA\n",
    "\n",
    "eta_output = 0.05 #parameter EWA output layer\n",
    "\n",
    "Nb_simu = 100 #number of simulations\n",
    "\n",
    "expert2 = 'PWA' #choose 'EWA' for results with EWA\n",
    "\n",
    "accuracy = np.zeros((Nb_simu))\n",
    "\n",
    "list_obj = [\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1],\n",
    "] #3 shapes, 3 colors\n",
    "\n",
    "M_out = 360\n",
    "M_test = 99\n",
    "\n",
    "task = 'easy1' #choose 'easy2' for second task\n",
    "\n",
    "if task == 'easy1':\n",
    "    propA = 1/3\n",
    "     #in A every obj with a 1 in 0\n",
    "\n",
    "if task == 'easy2':\n",
    "    propA = 1/2\n",
    "\n",
    "propB = 1 - propA\n",
    "\n",
    "nb_epoch = int(M_out / 9)\n",
    "accuracy_all = np.zeros((nb_epoch, Nb_simu))\n",
    "\n",
    "\n",
    "for nb in range(Nb_simu):\n",
    "    L=list_obj_random(list_obj,M_out) #list of objects by blocs with random order for each bloc\n",
    "#Simulation input neurons\n",
    "    #L_test = list_obj_random(list_obj, M_test)\n",
    "    prob_input = np.transpose(np.array([p*L for i in range(N)]), axes = (2,0,1) )\n",
    "    input_neurons_out = stats.bernoulli.rvs(prob_input)\n",
    "    #prob_input = np.transpose(np.array([p*L_test for i in range(N)]), axes = (2,0,1))\n",
    "    #input_neurons_test = stats.bernoulli.rvs(prob_input) #to test\n",
    "    P_input = np.sum(input_neurons_out, axis = 1) / N\n",
    "\n",
    "#parameters output layer\n",
    " \n",
    "    cum_gain_output = np.zeros((K_output))\n",
    "    cum_gain_mid2_to_output = np.zeros((K_output, K_input))\n",
    "\n",
    "    W_output = np.zeros((K_output, K_input, M_out+1))\n",
    "    W_output_not_renorm = np.zeros((K_output, K_input, M_out+1))\n",
    "    W_output[:, :, 0] += 1/K_input\n",
    "    W_output_not_renorm[:, :, 0] += 1\n",
    "\n",
    "#training output layer\n",
    "    ind_epoch = 0\n",
    "    for m in range(M_out):\n",
    "        obj = L[m,:]\n",
    "        gain_output = GainOutputEasyTask(K_output, K_input, P_input[:,m], obj, task)\n",
    "        cum_gain_mid2_to_output += gain_output\n",
    "        cum_gain_output += np.sum(W_output[:, :, m] * gain_output, axis = 1)\n",
    "        \n",
    "        if expert2 == \"EWA\":\n",
    "            W_output_not_renorm[ :, :, m+1] = EWA(W_output_not_renorm[:, :, m], eta_output, gain_output)\n",
    "            W_output[:,:, m+1] = (W_output_not_renorm[:, :, m+1].T / np.sum(W_output_not_renorm[:, :, m + 1], axis = 1)).T\n",
    "\n",
    "        else:\n",
    "            W_output_not_renorm[:, :, m+1] = PWA(para_PWA, K_output, K_input, cum_gain_output, cum_gain_mid2_to_output)\n",
    "            not_zero = np.where(np.sum(W_output_not_renorm[:,:,m+1], axis = 1) != 0)[0]\n",
    "            zero = np.where(np.sum(W_output_not_renorm[:,:,m+1], axis = 1) == 0)[0]\n",
    "            W_output[not_zero,:, m + 1] = (\n",
    "                W_output_not_renorm[not_zero, :, m + 1].T / np.sum(W_output_not_renorm[not_zero,:, m + 1], axis=1)\n",
    "                ).T\n",
    "            W_output[zero,:, m+1] = 1/K_input\n",
    "\n",
    "#test with new images\n",
    "        if m%9 == 0:\n",
    "            answers_test = np.zeros((M_test))\n",
    "            L_test = list_obj_random(list_obj, M_test)\n",
    "            prob_input = np.transpose(np.array([p*L_test for i in range(N)]), axes = (2,0,1))\n",
    "            input_neurons_test = stats.bernoulli.rvs(prob_input) #to test\n",
    "            for l in range(M_test):\n",
    "     \n",
    "            # Simulation output neurons (without Kalikow)\n",
    "                probas_output = np.sum(W_output[:,None,:,m+1] * input_neurons_test[:,:,l].T, axis = 2)\n",
    "                probas_output = np.clip(probas_output, 0, 1)\n",
    "                output_neurons = stats.bernoulli.rvs(probas_output)\n",
    "\n",
    "                P_output = np.sum(output_neurons, axis = 1) / N\n",
    "                chosen_class = np.where(P_output == np.max(P_output))[0]\n",
    "\n",
    "                obj = L_test[l,:]\n",
    "                if (chosen_class[0] == 0 and in_A(obj,task)) or (chosen_class[0] == 1 and in_B(obj,task)):\n",
    "                    answers_test[l] = 1\n",
    "            #accuracy[nb] = np.sum(answers_test)/M_test\n",
    "            accuracy_all[ind_epoch, nb] = np.sum(answers_test)/M_test\n",
    "            #print(nb, ind_epoch, accuracy_all[ind_epoch, nb])\n",
    "            ind_epoch+=1\n",
    "    print(nb)\n",
    "\n",
    "#np.save(f\"accuracy_{task}_{expert2}_0hid\", accuracy_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7d531",
   "metadata": {},
   "source": [
    "One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000 #number of timesteps\n",
    "p = 0.5 # spiking proba input neurons \n",
    "nu = 0.5 # bias\n",
    "\n",
    "K_input = 6 #number of input neurons\n",
    "\n",
    "K_output = 2  #number of output neurons\n",
    "\n",
    "para_PWA = 2 #parameter expert PWA\n",
    "\n",
    "eta_output = 0.05 #parameter EWA output layer\n",
    "eta_mid = 3\n",
    "\n",
    "Nb_simu = 100 #number of simulations\n",
    "\n",
    "expert2 = 'PWA'\n",
    "expert1 = 'PWA'\n",
    "\n",
    "accuracy = np.zeros((Nb_simu))\n",
    "\n",
    "list_obj = [\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1],\n",
    "] #3 shapes, 3 colors\n",
    "\n",
    "M_out = 360\n",
    "M_hid = 90\n",
    "M_sel = 18\n",
    "M_test = 99\n",
    "\n",
    "task = 'easy2' #choose 'easy1' for first task\n",
    "\n",
    "if task == 'easy1':\n",
    "    propA = 1/3\n",
    "     #in A every obj with a 1 in 0\n",
    "\n",
    "if task == 'easy2':\n",
    "    propA = 1/2\n",
    "\n",
    "propB = 1 - propA\n",
    "\n",
    "K_mid = int(K_input * (K_input - 1) /2)\n",
    "#K_mid_new = 9\n",
    "\n",
    "thresh = 0.1 #threshold to select neurons\n",
    "\n",
    "indices = np.arange(K_input)\n",
    "i, j = np.meshgrid(indices, indices)\n",
    "mask = i < j\n",
    "l_mid = np.column_stack((i[mask], j[mask]))\n",
    "\n",
    "nb_epoch = int(M_out / 9)\n",
    "\n",
    "accuracy_all = np.zeros((nb_epoch, Nb_simu))\n",
    "\n",
    "for nb in range(Nb_simu):\n",
    "    #print(nb)\n",
    "    L_out=list_obj_random(list_obj,M_out) #list of objects by blocs with random order for each bloc\n",
    "    L_hid = list_obj_random(list_obj,M_hid)\n",
    "    L_sel = list_obj_random(list_obj,M_sel)\n",
    "\n",
    "    #Simulation input neurons\n",
    "    #to train mid neurons\n",
    "    prob =  np.transpose(np.array([p*L_hid for i in range(N)]), axes = (2,0,1) )\n",
    "    input_neurons_mid = stats.bernoulli.rvs(prob) #to train mid neurons\n",
    "\n",
    "    #to sel mid neurons\n",
    "    prob =  np.transpose(np.array([p*L_sel for i in range(N)]), axes = (2,0,1) )\n",
    "    input_neurons_sel = stats.bernoulli.rvs(prob) \n",
    "\n",
    "    #to train output neurons\n",
    "    prob_input = np.transpose(np.array([p*L_out for i in range(N)]), axes = (2,0,1) )\n",
    "    input_neurons_out = stats.bernoulli.rvs(prob_input)\n",
    "\n",
    "\n",
    "    #Parameters mid neurons\n",
    "    W_mid = np.zeros((K_mid,K_input,M_hid+1))\n",
    "    W_mid[:,:,0] = 1/K_input\n",
    "    W_mid_not_renorm = np.zeros((K_mid, K_input, M_hid+1))\n",
    "    W_mid_not_renorm[:, :, 0] += 1\n",
    "\n",
    "    cum_gain_mid = np.zeros((K_mid))\n",
    "    cum_gain_input_to_mid = np.zeros((K_mid,K_input))\n",
    "\n",
    "#training mid neurons\n",
    "\n",
    "    for m in range(M_hid):\n",
    "        \n",
    "        gain_mid = GainMid(np.arange(K_mid),K_mid,K_input,input_neurons_mid[:,:,m], l_mid) #(K_mid,K_input)\n",
    "        cum_gain_input_to_mid += gain_mid\n",
    "        cum_gain_mid += np.sum(W_mid[:,:,m] * gain_mid, axis = 1)\n",
    "\n",
    "        if expert1 == \"EWA\":\n",
    "            W_mid_not_renorm[:, :, m + 1] = EWA(W_mid_not_renorm[:, :, m], eta_mid, gain_mid)\n",
    "            W_mid[:, :, m + 1] = (W_mid_not_renorm[:, :, m + 1].T / np.sum(W_mid_not_renorm[:, :, m + 1], axis=1)).T\n",
    "            #W_mid[:, :, m+1] = 1/K_mid\n",
    "        else:\n",
    "            W_mid_not_renorm[:, :, m + 1] = PWA(para_PWA, K_mid, K_input, cum_gain_mid, cum_gain_input_to_mid) \n",
    "            not_zero = np.where(np.sum(W_mid_not_renorm[:,:,m+1], axis = 1) != 0)[0]\n",
    "            zero = np.where(np.sum(W_mid_not_renorm[:,:,m+1], axis = 1) == 0)[0]\n",
    "            W_mid[not_zero, :, m + 1] = (W_mid_not_renorm[not_zero, :, m + 1].T / np.sum(W_mid_not_renorm[not_zero, :, m + 1], axis=1)).T\n",
    "            W_mid[zero, :, m+1] = 1/K_input\n",
    "                \n",
    "    #selection mid neurons\n",
    "\n",
    "    prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid[:,:,M_hid], input_neurons_sel)\n",
    "    clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "    mid_neurons_sel = stats.bernoulli.rvs(clipped_probas_mid)\n",
    "    P_mid = np.sum(mid_neurons_sel, axis=1) / N\n",
    "    max_P = np.max(P_mid, axis = 1 )\n",
    "    max_P_sorted = np.sort(max_P)\n",
    "\n",
    "    #x = max_P_sorted[K_mid-K_mid_new] \n",
    "    x = thresh\n",
    "    mid_neur_ok = np.where(max_P >= x)[0] #selected neurons\n",
    "    K_mid_new = np.shape(mid_neur_ok)[0]\n",
    "\n",
    "    mid_neur = mid_neur_ok\n",
    "    mid_neur = np.sort(mid_neur)\n",
    "\n",
    "    prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid[mid_neur,:,M_hid], input_neurons_out)\n",
    "    clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "    mid_neurons_out=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "    P_mid = np.sum(mid_neurons_out, axis = 1) / N\n",
    "\n",
    "    #parameters output\n",
    "    \n",
    "    cum_gain_output = np.zeros((K_output))\n",
    "    cum_gain_mid2_to_output = np.zeros((K_output, K_mid_new))\n",
    "\n",
    "    W_output = np.zeros((K_output, K_mid_new, M_out+1))\n",
    "    W_output_not_renorm = np.zeros((K_output, K_mid_new, M_out+1))\n",
    "    W_output[:, :, 0] += 1/K_mid_new\n",
    "    W_output_not_renorm[:, :, 0] += 1\n",
    "\n",
    "    ind_epoch = 0\n",
    "    for m in range(M_out):\n",
    "        obj = L_out[m,:]\n",
    "        gain_output = GainOutputEasyTask(K_output, K_mid_new, P_mid[:,m], obj, task) \n",
    "        cum_gain_mid2_to_output += gain_output\n",
    "        cum_gain_output += np.sum(W_output[:, :, m] * gain_output, axis = 1)\n",
    "            \n",
    "\n",
    "        if expert2 == \"EWA\":\n",
    "            W_output_not_renorm[ :, :, m+1] = EWA(W_output_not_renorm[:, :, m], eta_output, gain_output)\n",
    "            W_output[:,:, m+1] = (W_output_not_renorm[:, :, m+1].T / np.sum(W_output_not_renorm[:, :, m + 1], axis = 1)).T\n",
    "        else:\n",
    "            W_output_not_renorm[:, :, m+1] = PWA(para_PWA, K_output, K_mid_new, cum_gain_output, cum_gain_mid2_to_output)\n",
    "                \n",
    "            not_zero = np.where(np.sum(W_output_not_renorm[:,:,m+1], axis = 1) != 0)[0]\n",
    "            zero = np.where(np.sum(W_output_not_renorm[:,:,m+1], axis = 1) == 0)[0]\n",
    "            W_output[not_zero,:, m + 1] = (\n",
    "                W_output_not_renorm[not_zero, :, m + 1].T / np.sum(W_output_not_renorm[not_zero,:, m + 1], axis=1)\n",
    "                ).T\n",
    "            W_output[zero,:, m+1] = 1/K_mid_new\n",
    "            \n",
    "        \n",
    "        if m%9 == 0:\n",
    "            #to test \n",
    "            L_test = list_obj_random(list_obj,M_test)\n",
    "            prob_input = np.transpose(np.array([p*L_test for i in range(N)]), axes = (2,0,1) )\n",
    "            input_neurons_test = stats.bernoulli.rvs(prob_input) \n",
    "\n",
    "\n",
    "            #test with new images\n",
    "            prob_mid = -nu + np.einsum('ai, itm -> atm', W_mid[mid_neur,:,-1], input_neurons_test)\n",
    "            clipped_probas_mid = np.clip(prob_mid, 0, 1)\n",
    "            mid_neurons_test=stats.bernoulli.rvs(clipped_probas_mid)\n",
    "\n",
    "            answers_test = np.zeros((M_test))\n",
    "            for l in range(M_test):\n",
    "     \n",
    "            # Simulation output neurons (without Kalikow)\n",
    "                probas_output = np.sum(W_output[:,None,:,m+1] * mid_neurons_test[:,:,l].T, axis = 2)\n",
    "                probas_output = np.clip(probas_output, 0, 1)\n",
    "                output_neurons = stats.bernoulli.rvs(probas_output)\n",
    "\n",
    "                P_output = np.sum(output_neurons, axis = 1) / N\n",
    "                chosen_class = np.where(P_output == np.max(P_output))[0]\n",
    "\n",
    "                obj = L_test[l,:]\n",
    "                if (chosen_class[0] == 0 and in_A(obj,task)) or (chosen_class[0] == 1 and in_B(obj,task)):\n",
    "                    answers_test[l] = 1\n",
    "            accuracy_all[ind_epoch, nb] = np.sum(answers_test)/M_test\n",
    "            ind_epoch+=1\n",
    "        \n",
    "    print(nb)\n",
    "\n",
    "#np.save(f\"accuracy_{task}_{expert2}_1hid\", accuracy_all)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
